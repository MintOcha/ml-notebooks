{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tinkercademy/ml-notebooks/blob/main/Generative AI/06_Diffusion_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEV22Mj-VoIz"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ThiagoLira/ToyDiffusion.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b-bSgjj3XASD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from ToyDiffusion.diffusion import q_sample, posterior_q, Denoising, denoise_with_mu\n",
        "from ToyDiffusion.utils import pack_data, unpack_1d_data, scatter_pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6zGTFBxc5Ts"
      },
      "source": [
        "Uses GPU if it's available, and CPU otherwise. (GPU would be faster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-87Rb7QTVoI0"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv__OXkFc9-G"
      },
      "source": [
        "Generates pixels to represent the image entered into the function scatter_pixels.\n",
        "\n",
        "The graph is then scaled and transformed to fit.\n",
        "\n",
        "The original image used was https://www.infomoney.com.br/wp-content/uploads/2019/06/homer-simpson.jpg?resize=900%2C515&quality=50&strip=all.\n",
        "\n",
        "Try it out, and try other images too!\n",
        "\n",
        "NOTE: Colab may not be able to handle complex images (especially with colour) as it would generate too many points on the graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dXI4ulgfVoI1"
      },
      "outputs": [],
      "source": [
        "x,y = scatter_pixels('spiderman.png')\n",
        "x = [x/25 -3 for x in x]\n",
        "y = [y/25 -2 for y in y]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tONVpVFJVoI1"
      },
      "source": [
        "## Scatter plot of data we will try to train the model to generate from random noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1e2erMMcVoI1"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "ax = sns.scatterplot(x=x,y=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DNthR4HDVoI2"
      },
      "outputs": [],
      "source": [
        "## Store the axes view limits to plot the result later\n",
        "y_ax = ax.get_ylim()\n",
        "x_ax = ax.get_xlim()\n",
        "axes = (x_ax,y_ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YdCKLTQzVoI2"
      },
      "outputs": [],
      "source": [
        "# send data to device\n",
        "one_d_data = pack_data(x,y)\n",
        "x_init = torch.tensor(one_d_data).to(torch.float32).to(device)\n",
        "\n",
        "DATA_SIZE = len(x_init)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Eu35qXBVoI2"
      },
      "source": [
        "# Diffusion Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ItbMwGRgVoI2"
      },
      "outputs": [],
      "source": [
        "beta_start = .0004\n",
        "beta_end = .02\n",
        "num_diffusion_timesteps = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FesLv6f-VoI2"
      },
      "outputs": [],
      "source": [
        "from operator import mul\n",
        "from functools import reduce \n",
        "\n",
        "betas = np.linspace(beta_start ** 0.5, beta_end ** 0.5, num_diffusion_timesteps) ** 2\n",
        "alphas = 1 - betas\n",
        "\n",
        "# send parameters to device\n",
        "betas = torch.tensor(betas).to(torch.float32).to(device)\n",
        "alphas = torch.tensor(alphas).to(torch.float32).to(device)\n",
        "\n",
        "# alpha_bar_t is the product of all alpha_ts from 0 to t\n",
        "list_bar_alphas = [alphas[0]]\n",
        "for t in range(1,num_diffusion_timesteps):\n",
        "    list_bar_alphas.append(reduce(mul,alphas[:t]))\n",
        "    \n",
        "list_bar_alphas = torch.cumprod(alphas, axis=0).to(torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0YX55i_VoI2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdfcSQmdVoI3"
      },
      "source": [
        "## Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DIej0ka7VoI3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Try varying this!\n",
        "training_steps_per_epoch = 40\n",
        "\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "denoising_model = Denoising(DATA_SIZE, num_diffusion_timesteps).to(device)\n",
        "# disgusting hack to put embedding layer on 'device' as well, as it is not a pytorch module!\n",
        "denoising_model.emb = denoising_model.emb.to(device)\n",
        "optimizer = optim.AdamW(denoising_model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9Q8wifjwbPP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQGsvZ23VoI3",
        "outputId": "beffd823-bfe1-4cc0-da21-6a0a85ccad75"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch: 49 Loss: 0.05617253854870796: 100%|██████████| 50/50 [02:47<00:00,  3.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Try varying this!\n",
        "EPOCH_COUNT = 50\n",
        "\n",
        "pbar = tqdm(range(EPOCH_COUNT))\n",
        "for epoch in pbar:  # loop over the dataset multiple times\n",
        "    \n",
        "    running_loss = 0.0\n",
        "    # sample a bunch of timesteps\n",
        "    Ts = np.random.randint(1,num_diffusion_timesteps, size=training_steps_per_epoch)\n",
        "    for _, t in enumerate(Ts):\n",
        "        # produce corrupted sample\n",
        "        q_t = q_sample(x_init, t, list_bar_alphas, device)\n",
        "                \n",
        "        # calculate the mean and variance of the posterior forward distribution q(x_t-1 | x_t,x_0)\n",
        "        mu_t, cov_t = posterior_q(x_init, q_t, t, alphas, list_bar_alphas, device)\n",
        "        # get just first element from diagonal of covariance since they are all equal\n",
        "        sigma_t = cov_t[0][0]\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "  \n",
        "        mu_theta = denoising_model(q_t , t)\n",
        "        loss = criterion(mu_t, mu_theta)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.detach()\n",
        "    pbar.set_description('Epoch: {} Loss: {}'.format(epoch, running_loss/training_steps_per_epoch))\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkgbMVMNVoI3"
      },
      "source": [
        "### Reserve-Diffuse one Sample of Noise!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij-eQmJsVoI3",
        "outputId": "8eeb7c4f-5a40-4223-d291-2eb192aa3d27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 30/30 [00:00<00:00, 34.19it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm \n",
        "data = torch.distributions.MultivariateNormal(loc=torch.zeros(DATA_SIZE),covariance_matrix=torch.eye(DATA_SIZE)).sample().to(device)\n",
        "\n",
        "for t in tqdm(range(0,num_diffusion_timesteps)):\n",
        "    data = denoise_with_mu(denoising_model,data,num_diffusion_timesteps-t-1, alphas, list_bar_alphas, DATA_SIZE, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk5gOEUFVoI3"
      },
      "outputs": [],
      "source": [
        "data2 = data.detach().cpu().numpy()\n",
        "x_new, y_new = unpack_1d_data(data2)\n",
        "\n",
        "import seaborn as sns\n",
        "sns.scatterplot(x=x_new,y=y_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNZRqZgGVoI4"
      },
      "source": [
        "### Create an AWESOME HD 24fps GIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdkWeVggVoI4"
      },
      "outputs": [],
      "source": [
        "!pip install celluloid\n",
        "\n",
        "import numpy as np\n",
        "from celluloid import Camera\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig = plt.figure()\n",
        "camera = Camera(fig)\n",
        "\n",
        "# animation draws one data point at a time\n",
        "for d in range(1, num_diffusion_timesteps):\n",
        "    data = denoise_with_mu(denoising_model,data,num_diffusion_timesteps-d, alphas, list_bar_alphas, DATA_SIZE, device)\n",
        "    data_plot = data.detach().cpu().numpy()\n",
        "    x_new, y_new = unpack_1d_data(data_plot)\n",
        "    graph = sns.scatterplot(x=x_new,y=y_new,palette=['green'])\n",
        "    graph.set_xlim(axes[0])\n",
        "    graph.set_ylim(axes[1])\n",
        "    camera.snap()\n",
        "\n",
        "anim = camera.animate(blit=False)\n",
        "anim.save('output.gif',fps=24, dpi=120)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fcoQEdoHVoI4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmZVJRJ4wdAR"
      },
      "source": [
        "## **Exercise:**\n",
        "\n",
        "\n",
        "\n",
        "1.   Try various images!\n",
        "2.   Try changing the values of variables like EPOCH_COUNT or training_steps_per_epoch, what do you observe?\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
